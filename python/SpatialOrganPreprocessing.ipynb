{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#automatically reload stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import simplejson\n",
    "import Utils\n",
    "import matplotlib.pyplot as plt\n",
    "from SpatialPreprocessing import *\n",
    "from Autoencoders import autoencode\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the organ info and save it\n",
    "spatial_files = load_spatial_files()\n",
    "od = OrganData()\n",
    "pdict = od.process_cohort_spatial_dict(spatial_files)\n",
    "np_dict_to_json(pdict,Const.processed_organ_json)\n",
    "print(pdict)\n",
    "del pdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the dict is being saved properly\n",
    "pdata = load_pdict()\n",
    "pdata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get a dict of denoised arrays for each type of organ\n",
    "data = autoencode(pdata, ['distances','volume','centroids','mean_dose'], train=False)\n",
    "print()\n",
    "for k,v in data.items():\n",
    "    print(k)\n",
    "    for kk,vv in v.items():\n",
    "        print(kk,'array->', 'mean:', np.round(vv.mean(),5),'std', np.round(vv.std(),5), 'shape:',vv.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = data['distances']['denoised']\n",
    "vols = data['volume']['denoised']\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_tssim(x,y,v = None, w = None):\n",
    "    #calculates local similarity within two numpy arrays\n",
    "    #ignores structure of the windows\n",
    "    #x, y are base variables (distances) for patients 1 and 2\n",
    "    #v and w are volumes for patients 1 and 2\n",
    "    #should all be 1-dimensional for original intended use\n",
    "    c1 = .000001\n",
    "    c2  = .000001\n",
    "    x = x\n",
    "    y = y\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "    covariance = np.cov(x,y)\n",
    "    numerator = (2*mean_x*mean_y + c1) * (covariance[0,1] + covariance[1,0] + c2)\n",
    "    denominator = (mean_x**2 + mean_y**2 + c1)*(np.var(x) + np.var(y) + c2)\n",
    "    if v is not None and w is not None:\n",
    "        mean_v = np.mean(v)\n",
    "        mean_w = np.mean(w)\n",
    "        numerator *= (2*mean_v*mean_w + c1)\n",
    "        denominator *= (mean_v**2 + mean_w**2 + c1)\n",
    "    if denominator > 0:\n",
    "        return numerator/denominator\n",
    "    else:\n",
    "        print('error, zero denomiator in ssim function')\n",
    "        return 0\n",
    "    \n",
    "def get_adjacency_list(dist_array, window_size = 50, gtvname = \"GTV\"):\n",
    "    #takes distance array (n_patients) x (n_organs + gtv) x (n_organs)\n",
    "    #specific dimensions are flexible but the above is the format I'm writting it for\n",
    "    #returns a list of (n_organs + gtv) arrays with the indeces of organs withing window_size distance\n",
    "    mean_dists = np.nanmean(dists,axis=0)\n",
    "    adjacency_list = []\n",
    "    for organ_row in mean_dists:\n",
    "        #gets indeces for organs within a certian distance\n",
    "        #will index like dist_array[:,organ_row_idx,adjacent_organs]\n",
    "        adjacent_organs = np.argwhere(organ_row < window_size)\n",
    "        adjacency_list.append(adjacent_organs.ravel())\n",
    "    return adjacency_list\n",
    "\n",
    "def pairwise_mean_local_similarity(d1, d2, v1, v2, adjacency_list, local_sim_func = None):\n",
    "    #d1, d2 are min_distance arrays of shape (n_organs + <optional gtv>) x (n_organs)\n",
    "    #v1 v2 are volume arrays of shape (n_organs + <optional_gtv>) x 1\n",
    "    #adjacency list should be a list of (n_organs + <optional gtv>) indices for dim2\n",
    "    #local sim func should take 2 vectors for distances and two volumes\n",
    "    assert(d1.ndim == d2.ndim)\n",
    "    sims = np.empty((len(adjacency_list),))\n",
    "    if local_sim_func is None:\n",
    "        local_sim_func = local_tssim\n",
    "    for i,adjacency in enumerate(adjacency_list):\n",
    "        od1 = d1[i,adjacency]\n",
    "        od2 = d2[i,adjacency]\n",
    "        ov1 = v1[i]\n",
    "        ov2 = v2[i]\n",
    "        sim = local_sim_func(od1,od2,ov1,ov2)\n",
    "        sims[i] = sim\n",
    "    return sims.mean()\n",
    "        \n",
    "def pairwise_tssim_job(p1, p2, dist_array, vol_array, adjacency_list):\n",
    "    #wrapper for using similarity using multithreading\n",
    "    #only works this way becuase it has to be pickled\n",
    "    d1 = dist_array[p1]\n",
    "    d2 = dist_array[p2]\n",
    "    v1 = vol_array[p1]\n",
    "    v2 = vol_array[p2]\n",
    "    similarity = pairwise_mean_local_similarity(d1,d2,v1,v2,adjacency_list)\n",
    "    return p1, p2, similarity\n",
    "\n",
    "    \n",
    "def get_similarity_matrix(dist_array, vol_array, sim_func = None, max_jobs = 8):\n",
    "    #gets a n_items x n_items similarity matrix\n",
    "    #pairwise sim should take idx 1, idx 2, distance array, volme array, adjacency list\n",
    "    #default to tssim\n",
    "    if sim_func is None:\n",
    "        sim_func = pairwise_tssim_job\n",
    "        \n",
    "    x_items = dist_array.shape[0]\n",
    "    adjacency_list = get_adjacency_list(dist_array)\n",
    "    similarity_array = np.zeros((x_items, x_items))\n",
    "    \n",
    "    #get the number of available cpus\n",
    "    try:\n",
    "        available_cpus = len(os.sched_getaffinity(0))\n",
    "    except:\n",
    "        available_cpus = cpu_count() - 1\n",
    "    n_jobs = max(min(max_jobs, available_cpus), 1)\n",
    "    with Pool(n_jobs) as pool:\n",
    "        score_results = []\n",
    "        for p1 in range(x_items):\n",
    "            for p2 in range(p1 + 1,x_items):\n",
    "                score_result = pool.apply_async(sim_func,\n",
    "                                               args = (p1,p2,\n",
    "                                                      dist_array,\n",
    "                                                      vol_array,\n",
    "                                                      adjacency_list)\n",
    "                                               )\n",
    "                score_results.append(score_result)\n",
    "        for res in score_results:\n",
    "            (p1,p2,sim) = res.get(10000)\n",
    "            similarity_array[p1,p2] = sim\n",
    "    similarity_array += similarity_array.transpose()\n",
    "    return similarity_array\n",
    "    \n",
    "get_similarity_matrix(dists, vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
