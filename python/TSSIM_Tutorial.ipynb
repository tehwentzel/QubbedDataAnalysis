{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automatically reload stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the scripts I have to import the data,\n",
    "#save it as a intermediate json (patient_organ_data)\n",
    "#then denoise that and save it as a second json (patient_organ_data_denoise)\n",
    "#final version includes inputed values and the original mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils\n",
    "import matplotlib.pyplot as plt\n",
    "from OrganDataPreprocessing import CamprtOrganData\n",
    "import pprint\n",
    "import Formatting\n",
    "from Constants import Const\n",
    "import copy\n",
    "import Cluster\n",
    "import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/CAMPRT_Centroids/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Const.camprt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing doses set()\n",
      "missing distances {10153, 205, 10159, 281, 285}\n",
      "\n",
      "patient id 3\n",
      "dose file ../data/CAMPRT_Centroids/3/3_centroid.csv\n",
      "distance file ../data/CAMPRT_Centroids/3/3_distances.csv\n"
     ]
    }
   ],
   "source": [
    "#for the camprt data, centroids and distances are mapped to a folder for each patient\n",
    "#where the folder name is the patient id\n",
    "#this loads them and save them to a dict of the form {patient_id: {distances: distance_file, doses: doses_file}}\n",
    "def load_spatial_files(root = None):\n",
    "    #reads in the files for tumor centroids and ROI-tumor distances\n",
    "    #returns {'id': {'distances': <distfile>, 'doses': <centroid/dosefile>}}\n",
    "    #currently only returns patients with both ids\n",
    "    root = Const.camprt_dir if root is None else root\n",
    "    \n",
    "    try:\n",
    "        distance_files = glob(root + '**/*distances.csv')\n",
    "    except:\n",
    "        distance_files = []\n",
    "    try:\n",
    "        dose_files = glob(root + '**/*centroid*.csv')\n",
    "    except: \n",
    "        dose_files = []\n",
    "        \n",
    "    def file_id(file):\n",
    "        return max([int(x) for x in findall(\"[0-9]+\", file)])\n",
    "    \n",
    "    dose_dict = {file_id(f): f for f in dose_files}\n",
    "    dist_dict = {file_id(f): f for f in distance_files}\n",
    "    \n",
    "    dose_ids = set(dose_dict.keys())\n",
    "    dist_ids = set(dist_dict.keys())\n",
    "    shared_ids = dose_ids.intersection(dist_ids)\n",
    "    \n",
    "    #print which patients didn't have matches\n",
    "    dropped_ids = dose_ids.symmetric_difference(dist_ids)\n",
    "    if(len(dropped_ids) > 0):\n",
    "        print(\"missing doses\", dose_ids - shared_ids)\n",
    "        print(\"missing distances\", dist_ids - shared_ids)\n",
    "        \n",
    "    file_dict = {sid: {'doses': dose_dict.get(sid), 'distances': dist_dict.get(sid)} for sid in shared_ids}\n",
    "    return file_dict\n",
    "\n",
    "sfiles = load_spatial_files()\n",
    "print('')\n",
    "for k,v in sfiles.items():\n",
    "    print('patient id',k)\n",
    "    print('dose file',v['doses'])\n",
    "    print('distance file',v['distances'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROI</th>\n",
       "      <th>x coordinate</th>\n",
       "      <th>y coordinate</th>\n",
       "      <th>z coordinate</th>\n",
       "      <th>Structure Volume</th>\n",
       "      <th>Min Value</th>\n",
       "      <th>Mean Value</th>\n",
       "      <th>Max Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GTV-N</td>\n",
       "      <td>295.3126</td>\n",
       "      <td>226.5868</td>\n",
       "      <td>77.6118</td>\n",
       "      <td>13.1</td>\n",
       "      <td>64.13</td>\n",
       "      <td>71.90</td>\n",
       "      <td>76.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brainstem</td>\n",
       "      <td>258.4537</td>\n",
       "      <td>245.9965</td>\n",
       "      <td>48.1683</td>\n",
       "      <td>23.5</td>\n",
       "      <td>1.52</td>\n",
       "      <td>12.60</td>\n",
       "      <td>39.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cricoid_cartilage</td>\n",
       "      <td>255.2230</td>\n",
       "      <td>233.9010</td>\n",
       "      <td>98.3618</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.12</td>\n",
       "      <td>29.76</td>\n",
       "      <td>46.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cricopharyngeal_Muscle</td>\n",
       "      <td>256.0970</td>\n",
       "      <td>241.5970</td>\n",
       "      <td>98.5522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.60</td>\n",
       "      <td>30.93</td>\n",
       "      <td>43.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Esophagus</td>\n",
       "      <td>260.1786</td>\n",
       "      <td>265.2096</td>\n",
       "      <td>119.2499</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.79</td>\n",
       "      <td>33.52</td>\n",
       "      <td>42.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ROI  x coordinate  y coordinate  z coordinate  \\\n",
       "0                   GTV-N      295.3126      226.5868       77.6118   \n",
       "1               Brainstem      258.4537      245.9965       48.1683   \n",
       "2       Cricoid_cartilage      255.2230      233.9010       98.3618   \n",
       "3  Cricopharyngeal_Muscle      256.0970      241.5970       98.5522   \n",
       "4               Esophagus      260.1786      265.2096      119.2499   \n",
       "\n",
       "   Structure Volume  Min Value  Mean Value  Max Value  \n",
       "0              13.1      64.13       71.90      76.19  \n",
       "1              23.5       1.52       12.60      39.70  \n",
       "2               4.5       8.12       29.76      46.31  \n",
       "3               1.0      11.60       30.93      43.08  \n",
       "4               4.6       3.79       33.52      42.33  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dose files for this version are structured with coordinates, volume, and min/max/mean dose for each roi\n",
    "#also not that the GTVXX are tumors, names are inconsistent for these and need cleaning\n",
    "#GTVn is a nodal (lymph node) tumor, GTVp is a primary tumor\n",
    "pd.read_csv(sfiles[3]['doses']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference ROI</th>\n",
       "      <th>Target ROI</th>\n",
       "      <th>Eucledian Distance (mm)</th>\n",
       "      <th>Phi (degrees)</th>\n",
       "      <th>Theta (degrees)</th>\n",
       "      <th>% of Target Overlap</th>\n",
       "      <th>Eucledian Distance (mm) 5th Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GTV-N</td>\n",
       "      <td>Brainstem</td>\n",
       "      <td>39.1372</td>\n",
       "      <td>11.0494</td>\n",
       "      <td>-157.0113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.4944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GTV-N</td>\n",
       "      <td>Cricoid_cartilage</td>\n",
       "      <td>17.7550</td>\n",
       "      <td>-3.1798</td>\n",
       "      <td>180.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GTV-N</td>\n",
       "      <td>Cricopharyngeal_Muscle</td>\n",
       "      <td>20.8533</td>\n",
       "      <td>-8.5625</td>\n",
       "      <td>-162.4744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GTV-N</td>\n",
       "      <td>Esophagus</td>\n",
       "      <td>36.5443</td>\n",
       "      <td>-20.1214</td>\n",
       "      <td>-151.5571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GTV-N</td>\n",
       "      <td>Extended_Oral_Cavity</td>\n",
       "      <td>15.7466</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>150.2551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reference ROI              Target ROI  Eucledian Distance (mm)  \\\n",
       "0         GTV-N               Brainstem                  39.1372   \n",
       "1         GTV-N       Cricoid_cartilage                  17.7550   \n",
       "2         GTV-N  Cricopharyngeal_Muscle                  20.8533   \n",
       "3         GTV-N               Esophagus                  36.5443   \n",
       "4         GTV-N    Extended_Oral_Cavity                  15.7466   \n",
       "\n",
       "   Phi (degrees)  Theta (degrees)  % of Target Overlap  \\\n",
       "0        11.0494        -157.0113                  0.0   \n",
       "1        -3.1798         180.0000                  0.0   \n",
       "2        -8.5625        -162.4744                  0.0   \n",
       "3       -20.1214        -151.5571                  0.0   \n",
       "4         0.0000         150.2551                  0.0   \n",
       "\n",
       "   Eucledian Distance (mm) 5th Percentile  \n",
       "0                                 46.4944  \n",
       "1                                 20.1082  \n",
       "2                                 23.4563  \n",
       "3                                 43.1742  \n",
       "4                                 27.0794  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Distances are paired ROI inter-region distances. \n",
    "#This is the minimum distance between the outer edges of the organ\n",
    "#Note this is also annoying to work with\n",
    "pd.read_csv(sfiles[3]['distances']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rename cols {'Sructure Volume': 'Structure Volume', 'Min value': 'Min Value'}\n",
      "rename cols {'Mean Volume': 'Mean Value', 'Max Volume': 'Max Value'}\n",
      "error reading patient 27\n",
      "'<' not supported between instances of 'float' and 'str'\n",
      "rename cols {'Mean Value ': 'Mean Value'}\n",
      "rename cols {'Mean Value ': 'Mean Value'}\n",
      "rename cols {'Max Vlaue': 'Max Value'}\n",
      "rename cols {'min Value': 'Min Value'}\n",
      "rename cols {'Max Vlaue': 'Max Value'}\n",
      "rename cols {'Mean value': 'Mean Value'}\n",
      "rename cols {'MinValue': 'Min Value'}\n",
      "rename cols {'Mean value': 'Mean Value'}\n",
      "rename cols {'Mean Dose': 'Mean doses'}\n",
      "rename cols {'Mean_dose': 'Mean doses'}\n",
      "rename cols {'mean dose': 'Mean doses'}\n",
      "rename cols {'mean dose': 'Mean doses'}\n",
      "rename cols {'mean dose': 'Mean doses'}\n",
      "rename cols {'mean doses': 'Mean doses'}\n",
      "rename cols {'mean doses': 'Mean doses'}\n",
      "rename cols {'min Value': 'Min Value'}\n",
      "rename cols {'Min Volume': 'Min Value', 'Mean Volume': 'Mean Value', 'Max Volume': 'Max Value'}\n",
      "rename cols {'Mean value': 'Mean Value'}\n",
      "renamed organs {'Rt_Sternocleidmastoid_M': 'Rt_Sternocleidomastoid_M'}\n",
      "renamed organs {'Rt_Sternocleidmastoid_M': 'Rt_Sternocleidomastoid_M'}\n",
      "renamed organs {'Rt_Sternocleidmastoid_M': 'Rt_Sternocleidomastoid_M'}\n",
      "renamed organs {'Rt_Sternocleidmastoid_M': 'Rt_Sternocleidomastoid_M'}\n",
      "renamed organs {'Rt_Sternocleidmastoid_M': 'Rt_Sternocleidomastoid_M'}\n",
      "renamed organs {'Rt_Sternocleidmastoid_M': 'Rt_Sternocleidomastoid_M'}\n",
      "rename cols {'Min value': 'Min Value', 'Mean value': 'Mean Value'}\n",
      "error reading patient 10029\n",
      "bad operand type for unary -: 'str'\n",
      "rename cols {'Strucutre Volume': 'Structure Volume'}\n",
      "rename cols {'Structue Volume': 'Structure Volume'}\n",
      "rename cols {'mean Value': 'Mean Value'}\n",
      "rename cols {'Min Value ': 'Min Value'}\n",
      "rename cols {' Max Value': 'Max Value'}\n",
      "rename cols {'Mea Value': 'Mean Value'}\n",
      "rename cols {'Max Volume': 'Max Value'}\n",
      "rename cols {'Min Volume': 'Min Value', 'Mean Volume': 'Mean Value'}\n",
      "rename cols {'Min Vlaue': 'Min Value'}\n",
      "rename cols {'Min value': 'Min Value'}\n",
      "rename cols {'Max Volume': 'Max Value'}\n",
      "rename cols {'Strucutre Volume': 'Structure Volume'}\n",
      "rename cols {'max Value': 'Max Value'}\n",
      "rename cols {'Mean Volume': 'Mean Value', 'Max Volume': 'Max Value'}\n",
      "rename cols {'Structue Volume': 'Structure Volume'}\n",
      "rename cols {'min Value': 'Min Value'}\n",
      "rename cols {'Mean Volume': 'Mean Value', 'Max Volume': 'Max Value'}\n",
      "rename cols {'Min Value ': 'Min Value', 'Max Value ': 'Max Value'}\n",
      "rename cols {'Min Value ': 'Min Value', 'Mean Value ': 'Mean Value', 'Max Value ': 'Max Value'}\n",
      "rename cols {'Max value': 'Max Value'}\n",
      "rename cols {'Max Value ': 'Max Value'}\n",
      "rename cols {'Min value': 'Min Value', 'Max Value ': 'Max Value'}\n",
      "rename cols {'Max Value ': 'Max Value'}\n",
      "rename cols {'y coordinate ': 'y coordinate'}\n",
      "renamed organs {'Brianstem': 'Brainstem'}\n",
      "rename cols {'Max Volume': 'Max Value'}\n",
      "rename cols {'mean doses': 'Mean doses'}\n",
      "rename cols {'Sturcture Volume': 'Structure Volume'}\n",
      "invalid patients [17, 39, 101, 115, 239, 10011, 10034, 10043, 10074, 10080, 10094, 10145, 10148, 10164, 10174, 10181, 2020]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['organs', 'patients'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the organ info and save it to a default format\n",
    "\n",
    "#In OrganDataPreprocessing I have a very complicated setup for processing a patient\n",
    "#which includes a bunch of manual error checkers. See that code for reference, but new Dicom data will have different preprocessing\n",
    "#In this print out, rename cols gives a list of things I renamed. You can see why I had to implement a generic spellchecking\n",
    "od = CamprtOrganData()\n",
    "pdict = od.process_cohort_spatial_dict(sfiles)\n",
    "pdict.keys()\n",
    "# Utils.np_dict_to_json(pdict,Const.processed_organ_json)\n",
    "# del pdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distances': [('Spinal_Cord', np.float64(1.81)),\n",
       "  ('Rt_Brachial_Plexus', np.float64(0.905)),\n",
       "  ('Thyroid_cartilage', np.float64(0.905)),\n",
       "  ('Lt_Parotid_Gland', np.float64(0.905)),\n",
       "  ('Rt_Ant_Digastric_M', np.float64(0.905)),\n",
       "  ('Brainstem', np.float64(0.4525)),\n",
       "  ('Rt_Parotid_Gland', np.float64(0.4525)),\n",
       "  ('Rt_Lateral_Pterygoid_M', np.float64(0.4525)),\n",
       "  ('Lt_Mastoid', np.float64(0.4525)),\n",
       "  ('Hyoid_bone', np.float64(0.4525)),\n",
       "  ('Glottic_Area', np.float64(0.4525))],\n",
       " 'volume': [('Spinal_Cord', np.float64(1.81)),\n",
       "  ('Esophagus', np.float64(0.905)),\n",
       "  ('Rt_Brachial_Plexus', np.float64(0.905)),\n",
       "  ('Thyroid_cartilage', np.float64(0.905)),\n",
       "  ('Lt_Parotid_Gland', np.float64(0.905)),\n",
       "  ('Rt_Ant_Digastric_M', np.float64(0.905)),\n",
       "  ('Cricoid_cartilage', np.float64(0.4525)),\n",
       "  ('Brainstem', np.float64(0.4525)),\n",
       "  ('Rt_Parotid_Gland', np.float64(0.4525)),\n",
       "  ('Rt_Lateral_Pterygoid_M', np.float64(0.4525)),\n",
       "  ('Lt_Mastoid', np.float64(0.4525)),\n",
       "  ('Hyoid_bone', np.float64(0.4525)),\n",
       "  ('Glottic_Area', np.float64(0.4525))],\n",
       " 'centroids': [('Spinal_Cord', np.float64(1.81)),\n",
       "  ('Rt_Brachial_Plexus', np.float64(0.905)),\n",
       "  ('Thyroid_cartilage', np.float64(0.905)),\n",
       "  ('Lt_Parotid_Gland', np.float64(0.905)),\n",
       "  ('Rt_Ant_Digastric_M', np.float64(0.905)),\n",
       "  ('Brainstem', np.float64(0.4525)),\n",
       "  ('Rt_Parotid_Gland', np.float64(0.4525)),\n",
       "  ('Rt_Lateral_Pterygoid_M', np.float64(0.4525)),\n",
       "  ('Lt_Mastoid', np.float64(0.4525)),\n",
       "  ('Hyoid_bone', np.float64(0.4525)),\n",
       "  ('Glottic_Area', np.float64(0.4525))],\n",
       " 'mean_dose': [('Spinal_Cord', np.float64(1.81)),\n",
       "  ('Rt_Brachial_Plexus', np.float64(0.905)),\n",
       "  ('Thyroid_cartilage', np.float64(0.905)),\n",
       "  ('Lt_Parotid_Gland', np.float64(0.905)),\n",
       "  ('Rt_Ant_Digastric_M', np.float64(0.905)),\n",
       "  ('Esophagus', np.float64(0.4525)),\n",
       "  ('Cricoid_cartilage', np.float64(0.4525)),\n",
       "  ('Brainstem', np.float64(0.4525)),\n",
       "  ('Rt_Parotid_Gland', np.float64(0.4525)),\n",
       "  ('Rt_Lateral_Pterygoid_M', np.float64(0.4525)),\n",
       "  ('Lt_Mastoid', np.float64(0.4525)),\n",
       "  ('Hyoid_bone', np.float64(0.4525)),\n",
       "  ('Glottic_Area', np.float64(0.4525))]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so this should check that the values make sense\n",
    "#currently it implies there is an issue but I don't know what\n",
    "def get_num_nans_per_organ(sdata):\n",
    "    #should return a list of the % of patients missing data for each organ\n",
    "    #for each entry type\n",
    "    olist = sdata['organs']\n",
    "    oarlist = olist + ['gtv']\n",
    "    allnan = {}\n",
    "    for key in ['distances','volume','centroids','mean_dose']:\n",
    "        nancount = {o: 0 for o in oarlist}\n",
    "        arr = Formatting.merged_spatial_array(sdata, key)\n",
    "        for i,aa in enumerate(arr):\n",
    "            #find missing organs for individual\n",
    "            all_nan = np.argwhere(np.isnan(aa).all(axis=1))\n",
    "            nanset = set([])\n",
    "            if len(all_nan) < 1:\n",
    "                continue\n",
    "            for arg in all_nan[0]:\n",
    "                nanorgan = oarlist[arg]\n",
    "                nancount[nanorgan] = nancount[nanorgan] + 1\n",
    "        nancount = [(k,np.round(100*nancount[k]/arr.shape[0],4)) for k,v in nancount.items() if v > 0]\n",
    "        nancount = sorted(nancount, key = lambda x: -x[1])\n",
    "        \n",
    "        allnan[key] = nancount\n",
    "    return allnan\n",
    "    \n",
    "get_num_nans_per_organ(pdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training stopped on epoch 3349\n",
      "OrganAutoEncoder(\n",
      "  (hidden_layers): Sequential(\n",
      "    (0): Linear(in_features=1845, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=20, bias=True)\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=20, out_features=100, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=100, out_features=200, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=200, out_features=1845, bias=True)\n",
      "    (13): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n",
      "tensor(0.1289, grad_fn=<MeanBackward0>)\n",
      "volume\n",
      "891.0 0.0 891.0 0.0\n",
      "891.0 0.0 \n",
      "\n",
      "distances\n",
      "207.62500079518182 -24.640625 207.625 -24.640625\n",
      "207.625 -24.640625 \n",
      "\n",
      "centroids\n",
      "658.3561 8.7422 658.3561 0.0\n",
      "658.3561 8.7422 \n",
      "\n",
      "mean_dose\n",
      "80.92 0.0 86.25 0.0\n",
      "80.92 0.0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('volume', (221, 41, 1)),\n",
       " ('volume_missing', (221, 41, 1)),\n",
       " ('distances', (221, 41, 40)),\n",
       " ('distances_missing', (221, 41, 40)),\n",
       " ('centroids', (221, 41, 3)),\n",
       " ('centroids_missing', (221, 41, 3)),\n",
       " ('mean_dose', (221, 41, 1)),\n",
       " ('mean_dose_missing', (221, 41, 1))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converts the json to a dictionary of arrays with all missing values imputed\n",
    "#imputation here is the denosing autoencoder (see TSSIM paper), which improves results a bit and fills in missing data\n",
    "#denoise alpha is the coefficient of how much of the denoising is done \n",
    "#using the autoencoder used to input missing values [0 = none, 1 = all]\n",
    "di = Formatting.DataInputer(denoise_alpha = 0)\n",
    "ddict = di.get_formatted_arrays(pdict,retrain=True)\n",
    "\n",
    "#ddict is a dictionary of format {volume|distances|centroids|mean_dose : np.array}\n",
    "#arrays are in teh shape n_patients, n_organs, n_channels\n",
    "#channels are e.g. 3 for centroids (x,y,z), n_organs - 1 (no gtv distances) for distances, and 1 for volume and mean dose\n",
    "[(k,v.shape) for k,v in ddict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_mean_reconstruction_error (%)</th>\n",
       "      <th>mean_denoised</th>\n",
       "      <th>std_denoised</th>\n",
       "      <th>shape_denoised</th>\n",
       "      <th>num_nan_denoised</th>\n",
       "      <th>num_negative_denoised</th>\n",
       "      <th>mean_original</th>\n",
       "      <th>std_original</th>\n",
       "      <th>shape_original</th>\n",
       "      <th>num_nan_original</th>\n",
       "      <th>num_negative_original</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>21.489422</td>\n",
       "      <td>18.24454</td>\n",
       "      <td>27.37419</td>\n",
       "      <td>(221, 41, 1)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.32490</td>\n",
       "      <td>27.51738</td>\n",
       "      <td>(221, 41, 1)</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distances</th>\n",
       "      <td>8.651396</td>\n",
       "      <td>42.63233</td>\n",
       "      <td>32.66252</td>\n",
       "      <td>(221, 41, 40)</td>\n",
       "      <td>0</td>\n",
       "      <td>15540</td>\n",
       "      <td>42.49418</td>\n",
       "      <td>32.79505</td>\n",
       "      <td>(221, 41, 40)</td>\n",
       "      <td>3506</td>\n",
       "      <td>16598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centroids</th>\n",
       "      <td>5.945143</td>\n",
       "      <td>173.50165</td>\n",
       "      <td>81.03168</td>\n",
       "      <td>(221, 41, 3)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173.53767</td>\n",
       "      <td>81.73428</td>\n",
       "      <td>(221, 41, 3)</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_dose</th>\n",
       "      <td>60.317162</td>\n",
       "      <td>43.06255</td>\n",
       "      <td>17.94863</td>\n",
       "      <td>(221, 41, 1)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.48905</td>\n",
       "      <td>19.56367</td>\n",
       "      <td>(221, 41, 1)</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           _mean_reconstruction_error (%)  mean_denoised  std_denoised  \\\n",
       "key                                                                      \n",
       "volume                          21.489422       18.24454      27.37419   \n",
       "distances                        8.651396       42.63233      32.66252   \n",
       "centroids                        5.945143      173.50165      81.03168   \n",
       "mean_dose                       60.317162       43.06255      17.94863   \n",
       "\n",
       "          shape_denoised  num_nan_denoised  num_negative_denoised  \\\n",
       "key                                                                 \n",
       "volume      (221, 41, 1)                 0                      0   \n",
       "distances  (221, 41, 40)                 0                  15540   \n",
       "centroids   (221, 41, 3)                 0                      0   \n",
       "mean_dose   (221, 41, 1)                 0                      0   \n",
       "\n",
       "           mean_original  std_original shape_original  num_nan_original  \\\n",
       "key                                                                       \n",
       "volume          18.32490      27.51738   (221, 41, 1)               131   \n",
       "distances       42.49418      32.79505  (221, 41, 40)              3506   \n",
       "centroids      173.53767      81.73428   (221, 41, 3)               141   \n",
       "mean_dose       42.48905      19.56367   (221, 41, 1)                90   \n",
       "\n",
       "           num_negative_original  \n",
       "key                               \n",
       "volume                         0  \n",
       "distances                  16598  \n",
       "centroids                      0  \n",
       "mean_dose                      0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the error on the neural net for inputing/denoising\n",
    "#only considers non-missing values\n",
    "#value are before performing clipping on the inputed values\n",
    "di.error_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GTVp',\n",
       "  {'volume': np.float64(10.8),\n",
       "   'mean_dose': np.float64(71.75),\n",
       "   'centroids': array([279.6041, 198.22  ,  54.5221]),\n",
       "   'distances': array([83.   , 27.97 , 41.62 , 82.5  , 59.4  , 53.4  , 35.6  , 20.47 ,\n",
       "          29.28 , 26.66 , 27.72 , 55.06 , 72.2  , 53.78 , 34.56 , 44.6  ,\n",
       "          57.3  , 18.39 , 36.75 , 12.84 , -3.973, -1.953, 12.16 , 19.34 ,\n",
       "          11.59 , -4.98 , 35.94 , 10.05 , -4.027,  1.953, -3.32 , 28.08 ,\n",
       "           2.5  ,  6.117, -3.906,  6.906, 23.94 , 58.1  , 58.62 , 49.88 ],\n",
       "         dtype=float16)}),\n",
       " ('GTVn',\n",
       "  {'volume': np.float64(4.6),\n",
       "   'mean_dose': np.float64(72.28),\n",
       "   'centroids': array([293.0174, 212.0342,  61.6571]),\n",
       "   'distances': array([52.2   , 29.42  ,  6.734 , 63.9   , 30.45  , 29.8   , 14.49  ,\n",
       "          14.945 , 43.4   , 20.02  , 11.66  , 59.22  , 89.7   , 66.7   ,\n",
       "          61.5   , 72.56  , 78.7   , -1.953 , 29.8   ,  0.9766, -4.367 ,\n",
       "          10.15  , 32.72  , 14.945 ,  9.34  ,  6.836 , 48.5   ,  7.875 ,\n",
       "          26.11  , 21.31  , 25.03  , 45.5   , 19.03  , 23.84  , 14.69  ,\n",
       "          10.88  , 58.6   , 84.6   , 89.2   , 41.84  ], dtype=float16)})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_pdict_gtvs(p):\n",
    "    gtvlist = []\n",
    "    for pid,pentry in p['patients'].items():\n",
    "        plist = []\n",
    "        for o,oentry in pentry.items():\n",
    "            if 'GTV' in o:\n",
    "                plist.append((o,oentry))\n",
    "        gtvlist.append((pid, plist))\n",
    "    return gtvlist\n",
    "\n",
    "#turn it into another dictionary again\n",
    "def inputed_data_dict(pdata, insert_gtvs = True):\n",
    "    pids = Formatting.get_sorted_pids(pdata)\n",
    "    organs = pdata['organs'] + ['gtv_composite']\n",
    "    main_keys = [k for k in ddict.keys() if '_missing' not in k]\n",
    "    mask_keys =[k for k in ddict.keys() if k not in main_keys]\n",
    "    make_dict = lambda keys: {int(p): {o: {k: np.nan for k in keys} for o in organs} for p in pids}\n",
    "    inputed_data = make_dict(main_keys)\n",
    "    data_mask = make_dict(mask_keys)\n",
    "    for k,varray in ddict.items():\n",
    "        for pid, v_row in zip(pids,varray):\n",
    "            for organ, o_col in zip(organs, v_row):\n",
    "                val = o_col\n",
    "                if len(val) <= 1:\n",
    "                    val = val[0]\n",
    "                if k in mask_keys:\n",
    "                    data_mask[int(pid)][organ][k.replace('_missing','')] = val\n",
    "                else:\n",
    "                    inputed_data[int(pid)][organ][k] = val\n",
    "    return_dict = {'organs': organs, 'patient_ids': pids, \n",
    "            'patients': inputed_data, 'mask': data_mask}\n",
    "    if insert_gtvs:\n",
    "        gtvset = extract_pdict_gtvs(pdata)\n",
    "        for pid,gtvs in gtvset:\n",
    "            for k,v in gtvs:\n",
    "                return_dict['patients'][int(pid)][k] = v\n",
    "    return return_dict\n",
    "\n",
    "#I'm going to be honest I have no idea what this does\n",
    "pdata = inputed_data_dict(pdict)\n",
    "[(k,v) for k,v in pdata['patients'][185].items() if 'GTV' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/patient_organ_data_denoised.json\n"
     ]
    }
   ],
   "source": [
    "#saves inputed_ddict\n",
    "print(Const.denoised_organ_json)\n",
    "# Utils.np_dict_to_json(pdata, Const.denoised_organ_json,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 52.66879085,  25.79168075,  30.69005651, ...,  67.63982458,\n",
       "          72.23524916,  30.47110926]],\n",
       "\n",
       "       [[ 56.42200181,  28.43251164,  37.34030398, ...,  63.8253658 ,\n",
       "          70.43469042,  35.31509627]],\n",
       "\n",
       "       [[ 56.38310161,  37.12186748,  48.15841121, ...,  67.45791375,\n",
       "          74.9777054 ,  37.44155612]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 26.8125    ,  24.578125  ,  13.328125  , ...,  73.125     ,\n",
       "          79.6875    ,  14.5546875 ]],\n",
       "\n",
       "       [[ 70.9375    ,  38.28125   ,  56.84375   , ..., 114.3125    ,\n",
       "         127.6875    ,  58.09375   ]],\n",
       "\n",
       "       [[ 65.125     ,  33.21875   ,  57.625     , ...,  78.1875    ,\n",
       "          81.8125    ,  43.71875   ]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def denoised_pdict_to_array(dpd,key,organ_list=None,pids=None):\n",
    "    patients = dpd['patients']\n",
    "    if organ_list is None:\n",
    "        organ_list = dpd['organs']\n",
    "    elif not Utils.iterable(organ_list):\n",
    "        organ_list = [organ_list]\n",
    "    if pids is None:\n",
    "        pids = dpd['patient_ids']\n",
    "    array = []\n",
    "    for pid in pids:\n",
    "        row = []\n",
    "        pentry = patients.get(pid)\n",
    "        for organ in organ_list:\n",
    "            odata = pentry.get(organ)\n",
    "            if odata is None:\n",
    "                row.append(0)\n",
    "            else:\n",
    "                oval = odata.get(key)\n",
    "                row.append(oval)\n",
    "        array.append(row)\n",
    "    return np.array(array)\n",
    "\n",
    "#converts the dictionary to arrays to use for prediction\n",
    "volumes = denoised_pdict_to_array(pdata,'volume')\n",
    "distances = denoised_pdict_to_array(pdata,'distances')\n",
    "denoised_pdict_to_array(pdata,'distances',organ_list =['gtv_composite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((221, 41), (221, 41, 40))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the end results here is that for the Tssim code, we want a distances in the form n_patients, n_organs + gtv, n_organs\n",
    "#and volumes of the form n_patients, n_organs + gtv\n",
    "# where n_organs is defined in Const.organ_list, I think\n",
    "volumes.shape, distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing patient 219 and patient 220: 0.59767621530192343\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.68403329, 0.62034641, ..., 0.73218146, 0.61149602,\n",
       "        0.59943214],\n",
       "       [0.68403329, 1.        , 0.5765213 , ..., 0.59996719, 0.56147283,\n",
       "        0.5637392 ],\n",
       "       [0.62034641, 0.5765213 , 1.        , ..., 0.60720091, 0.59766111,\n",
       "        0.60537348],\n",
       "       ...,\n",
       "       [0.73218146, 0.59996719, 0.60720091, ..., 1.        , 0.57902504,\n",
       "        0.56704878],\n",
       "       [0.61149602, 0.56147283, 0.59766111, ..., 0.57902504, 1.        ,\n",
       "        0.70330457],\n",
       "       [0.59943214, 0.5637392 , 0.60537348, ..., 0.56704878, 0.70330457,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes in a dictionary of arrays \n",
    "#returns a similarity matrix 0-1\n",
    "#n_jobs > 1 will try to multithread\n",
    "sim = Models.TssimSimilarity(n_jobs = 4)\n",
    "sim_matrix = sim.get_similarity_matrix(distances,volumes)\n",
    "sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 2, 4, 4, 3, 4, 4, 3, 4,\n",
       "       3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2,\n",
       "       3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 2, 2, 3, 2, 3, 2, 2, 3, 2, 3, 4, 3,\n",
       "       2, 3, 3, 4, 3, 3, 3, 1, 3, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3,\n",
       "       1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1,\n",
       "       1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1], dtype=int32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similarity CLusterer does heirarchical clustering based on a similarity matrix, the method used in the TSSIM paper\n",
    "#see https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html for what link does\n",
    "#see https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.fcluster.html for what criterion does\n",
    "clusters = Cluster.SimilarityClusterer(4,\n",
    "                                       link='ward',#linkage method, passed to scipy.cluster.heirarchy.linkage\n",
    "                                       criterion='maxclust',#criterion passed to scipy.cluster.heirarch.fcluster\n",
    "                                      ).fit_predict(sim_matrix)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([178, 158,  53, 148]),\n",
       " array([178,   0, 102,  41]),\n",
       " array([178, 175,  41, 102]),\n",
       " array([  0,   2, 178,   1]),\n",
       " array([178, 175, 119,  41])]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can also get the most similar patients using the TSSIM similarity matrix\n",
    "#there are two match_type options, the normal knn (default) and the version in the camprt paper (threshold)\n",
    "knn = Models.PatientKNN(\n",
    "    match_type = 'default',#default used standard k-nearest neighbors\n",
    "    default_n_matches=4,#number of neighbors is match_type = default\n",
    ")\n",
    "knn.get_matches(sim_matrix)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([178, 158]),\n",
       " array([178, 148]),\n",
       " array([178, 102]),\n",
       " array([178, 175,  41]),\n",
       " array([178, 175,  41])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = Models.PatientKNN(\n",
    "    match_type = 'threshold',#threshold takes a variable number of people\n",
    "    match_threshold=.8, #if similarity is above this value, patient is considered a neighbor\n",
    "    n_match_bounds=[1,3], #[min,max], lower and upper limit on the number of neighbors to return. \n",
    ")\n",
    "knn_matches = knn.get_matches(sim_matrix)\n",
    "[k for k in knn_matches if len(k) > 1][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient 3\n",
      "{'neighbors': [10071, 10009], 'cluster': np.int32(3), 'similarity': array([0.82076472, 0.78579307])}\n",
      "patient 4\n",
      "{'neighbors': [10071], 'cluster': np.int32(4), 'similarity': array([0.69965742])}\n",
      "patient 10\n",
      "{'neighbors': [10071], 'cluster': np.int32(4), 'similarity': array([0.69498467])}\n",
      "patient 11\n",
      "{'neighbors': [3], 'cluster': np.int32(4), 'similarity': array([0.66117242])}\n"
     ]
    }
   ],
   "source": [
    "#takes patient dictionary object and similarity matrix and returns a dictionary of neighbors, similarity scores, and clusters\n",
    "#which are the data needed in a camprt style interface\n",
    "#is similarity matrix is not passed, it computes it using tssim\n",
    "def predict_patients(dpd,\n",
    "                     sim = None, \n",
    "                     n_clusters = 4, #number of clusters to pass to SimilarityClusterer\n",
    "                     return_dict= True,#whether to return a results dict or just the predictions. \n",
    "                     **knn_args,\n",
    "                   ):\n",
    "    if sim is None:\n",
    "        volumes = denoised_pdict_to_array(pdata,'volume')\n",
    "        distances = denoised_pdict_to_array(pdata,'distances')\n",
    "        sim = Models.TssimSimilarity(n_jobs = 4).get_similarity_matrix(distances,volumes)\n",
    "    pids = dpd['patient_ids']\n",
    "    \n",
    "    clusterer = Cluster.SimilarityClusterer(n_clusters)\n",
    "    clusters = clusterer.fit_predict(sim)\n",
    "    \n",
    "    knn = Models.PatientKNN(**knn_args)\n",
    "    knn_matches = knn.get_matches(sim_matrix)\n",
    "    \n",
    "    sim_dict = {}\n",
    "    for i,pid in enumerate(pids):\n",
    "        entry = {}\n",
    "        entry['neighbors'] = [pids[ii] for ii in knn_matches[i]]\n",
    "        entry['cluster'] = clusters[i]\n",
    "        entry['similarity'] = sim[i,knn_matches[i]]\n",
    "        sim_dict[pid] = entry\n",
    "    if return_dict is False:\n",
    "        thing = sorted([(k,v['cluster']) for k,v in sim_dict.items()],key=lambda x: x[0])\n",
    "        return np.array([t[1] for t in thing])\n",
    "    return sim_dict\n",
    "\n",
    "#keyword arguments (besides sim) are passed to the PatientKnn constructure shown above\n",
    "pp = predict_patients(pdata,sim_matrix,\n",
    "                     match_type='threshold',\n",
    "                     match_threshold=.8\n",
    "                     )\n",
    "for i,(patient_id, res) in enumerate(pp.items()):\n",
    "    print('patient',patient_id)\n",
    "    print(res)\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 4, 4, 4, 4, 4, 3, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_patients(pdata,sim_matrix,\n",
    "                     match_type='default',\n",
    "                      return_dict=False\n",
    "                     )[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
